\chapter{The Simply Typed Lambda Calculus}
\label{chap: stlc}

The lambda calculus was invented by Church the 1930s \cite{church1932} to provide a logical foundation for 
mathematics. However, his original system was soon proved to have some logical inconsistencies \cite{kleene1935}. 
Church then published the section of his system meant for dealing with functions in isolation 
which he proved to be consistent. This portion of his original work is now known as the untyped 
lambda calculus. Later on, he published the simply typed lambda calculus \cite{church1940} which is also logically 
consistent although computationally weaker than its untyped counterpart. Although his original 
system was designed as a foundation for mathematics, it was largely overlooked by the mathematic 
community who preferred set theory. It wasn't until the 1960s that the $\lambda$-calculus was 
discovered to be a useful tool in computer science. \\

\noindent
The simply typed lambda calculus ($\lambda$-calculus) is regarded as the most basic functional programming language. 
It can be used both as a simple programming language with which we can execute computation, and 
also as a mathematical object which we can perform proofs upon. Both of these aspects are 
extremely useful to computer scientists. Modelling computation helps us to understand how a 
language works, and viewing a language as a mathematical object allows us to prove that it 
is safe. 

\section{Statics}

\begin{figure}[h]
    \begin{align*}
        Types \quad \tau \quad ::= \quad & 1 &\text{unit} \\
        & \tau_1 + \tau_2 &\text{sum} \\
        & \tau_1 \times \tau_2 &\text{product} \\
        & \tau_1 \rightarrow \tau_2 &\text{function} \\
        \\
        Terms \quad e \quad ::= \quad & x &\text{variable} \\
        & \LamInl{e} &\text{left injection} \\
        & \LamInr{e} &\text{right injection} \\
        & \LamCase{e}{x}{e_1}{y}{e_2} &\text{case} \\
        & \Tuple{e_1}{e_2} &\text{pair} \\
        & \Proj{e} &\text{left projection} \\
        & \Proj[2]{e} &\text{right projection} \\
        & \Lam{x}[\tau]{e} &\text{abstraction} \\
        & e_1 (e_2) &\text{application}
    \end{align*}
    \caption{Types and Terms for the $\lambda$-Calculus}
    \label{fig: tt stlc}
\end{figure}

\noindent
The simply typed lambda calculus is a language for working with functions. If we have some typing
relation $\Gamma \vdash x: \sigma$ this means that in the context $\Gamma$, $x$ has type $\sigma$,
and $x$ is said to be well-typed. We can see from \ref{fig: tt stlc} that we have three composite
types, and terms can take on specific forms, the rules for which are shown in \ref{fig: sr stlc}. The
sum type is used to represent disjoint union so if $\Gamma \vdash x: \tau_1 + \tau_2$ then the type 
of $x$ is either $\tau_1$ or $\tau_2$. The product type is used to represent pairs, so if we have
$\Gamma \vdash \langle e_1, e_2 \rangle : \tau_1 \times \tau_2$ then we know that we have both 
$e_1: \tau_1$ and $e_2: \tau_2$. Finally, the function type is of course used to represent functions
so if we have $\Lam{x}[\sigma]{e}: \sigma \rightarrow \tau$ then this is equivalent to having some 
function $f : \sigma \rightarrow \tau$ so we must have that $x: \sigma$ and $f(x) = e: \tau$. 
So our function $f$ takes in some parameter of type $\sigma$ and outputs a result with type $\tau$.\\

\noindent
The rules in \ref{fig: sr stlc} have premises on the top and conclusions on the bottom. So for any rule
we know that if we have everything above the line, then we can conclude anything below the line. Rules 
without any premises are called axioms and require no justification.
We take a constructor to be a rule which can create something of a certain type, and a destructor to be 
a rule which reduces something of that type to a simpler type. \\


\begin{figure}[h]
    \begin{mathpar}
        \inferH{Var}{
        }{
            \Gamma, \DeclVar{x}{\sigma} \vdash \DeclVar{x}{\sigma}
        }\qquad
        \inferH{Unit}{
        }{
            \Gamma \vdash \UnitV : 1
        }\\
        \inferH{In-l}{
            \Gamma \vdash e: \tau_1
        }{
            \Gamma \vdash \LamInl{e}: \tau_1 + \tau_2
        }\qquad
        \inferH{In-r}{
            \Gamma \vdash e: \tau_2
        }{
            \Gamma \vdash \LamInr{e}: \tau_1 + \tau_2
        }\\
        \inferH{Case}{
            \Gamma \vdash e: \tau_1 + \tau_2 \\
            \Gamma, x: \tau_1 \vdash e_1: \tau \\
            \Gamma, y: \tau_2 \vdash e_2: \tau
        }{
            \Gamma \vdash \LamCase{e}{x}{e_1}{y}{e_2}: \tau
        }\\
        \inferH{Pair}{
            \Gamma \vdash e_1: \tau_1 \\
            \Gamma \vdash e_2: \tau_2
        }{
            \Gamma \vdash \Tuple{e_1}{e_2} : \tau_1 \times \tau_2
        }\qquad
        \inferH{Prj-l}{
            \Gamma \vdash e: \tau_1 \times \tau_2
        }{
            \Gamma \vdash \Proj{e}: \tau_1
        }\qquad
        \inferH{Prj-r}{
            \Gamma \vdash e: \tau_1 \times \tau_2
        }{
            \Gamma \vdash \Proj[2]{e}: \tau_2
        }\\
        \inferH{Abs}{
            \Gamma, x: \sigma \vdash e: \tau
        }{
            \Gamma \vdash \Lam{x}[\sigma]{e}: \sigma \rightarrow \tau
        }\qquad
        \inferH{App}{
            \Gamma \vdash e_1: \sigma \rightarrow \tau \\
            \Gamma \vdash e_2: \sigma
        }{
            \Gamma \vdash e_1 (e_2): \tau
        }\\
    \end{mathpar}
    \caption{Static Rules for the $\lambda$-Calculus}
    \label{fig: sr stlc}
\end{figure}

\noindent
The \ruleref{Var} rule simply states that if we have $x: \sigma$ in some environment $\Gamma$, 
then we know $x$ has type $\sigma$. The \ruleref{Unit} rule states that if we have an empty pair, then this has 
the unit type, 1. \ruleref{In-r} is a constructor for the sum type which allows us to use injection 
to derive that $\LamInl{e}$ has type $\tau_1 + \tau_2$ given that $e$ has type $\tau_1$, and similarly for 
\ruleref{In-l}. The \ruleref{Case} rule is the destructor for the sum type which branches on either
side depending on the specific instance given. %???? strange explanation%
The \ruleref{Pair} rule allows us to construct a product type $\tau_1 \times \tau_2$ given two terms 
with each of those types. \ruleref{Prj-l} destructs some pair with a product type $\tau_1 \times \tau_2$ 
into a term with type $\tau_1$, and similarly \ruleref{Prj-r} will destruct the pair into a term 
with type $\tau_2$. 
The \ruleref{Abs} rule refers to lambda abstraction and is a constructor for the product type. It allows
us to create a function $\Lam{x}[\sigma]{e} \sigma \rightarrow \tau$ if we can obtain some $e$ of type $\tau$
from $\Gamma$ and $ x: \sigma$. The \ruleref{App} rule is the destructor of the function type, function 
application. If we have some function $e_1: \sigma \rightarrow \tau$ and some variable $e_2$ of type 
$\sigma$ then we can apply the function $e_1$ to $e_2$ and obtain a result with type $\tau$.
\\

\section{Dynamics}

\noindent
We know how the typing system works for the $\lambda$-calculus, but we also need to understand 
it's computational behaviour, i.e. the dynamics of a program. To understand these rules fully, we 
will need the substituition lemma. \\

\noindent
\textbf{Substituition:} If we have $\Gamma \vdash e: \tau$ and $\Gamma, x: \tau \vdash u: \sigma$, 
then $\Gamma \vdash u[e/x]: \sigma$. 

\begin{figure}
    \vspace*{-1em}
    \begin{align*}
        x[e/x] &\EqDef e &w[e/x] &\EqDef w \\\\
        \LamInl{u}[e/x] &\EqDef \LamInl{u[e/x]} &\LamInr{u}[e/x] &\EqDef \LamInr{u[e/x]} \\
        &\qquad \LamCase{u}{y}{e_1}{z}{e_2}[e/x] &\EqDef \LamCase{u[e/x]}{y}{e_1[e/x]}{z}{e_2[e/x]} \\\\
        \UnitV[e/x] &\EqDef \UnitV &\Tuple{e_1}{e_2}[e/x] &\EqDef \Tuple{e_1[e/x]}{e_2[e/x]} \\
        \Proj{u}[e/x] &\EqDef \Proj{u[e/x]} &\Proj[2]{u}[e/x] &\EqDef \Proj[2]{u[e/x]} \\\\
        (\Lam{w}{u})[e/x] &\EqDef \Lam{w}{u[e/x]} &(e_1 (e_2))[e/x] &\EqDef (e_1[e/x])(e_2[e/x]) \\      
    \end{align*}
    \caption{Substitution for the $\lambda$-Calculus}
    \label{fig: dr stlc}
\end{figure}

\noindent
Now we understand how substituition works, we can fully appreciate the dynamic rules 
for the $\lambda$-calculus which are shown below.

\begin{figure}[h]
    \begin{mathpar}
        \inferH{Val-Unit}{
        }{
            \UnitV \ \text{val}
        }\qquad
        \inferH{Val-In-l}{
        }{
            \LamInl{e} \ \text{val}
        }\qquad
        \inferH{Val-In-r}{
        }{
            \LamInr{e} \ \text{val}
        }\qquad
        \inferH{Val-Pair}{
        }{
            \Tuple{e_1}{e_2} \ \text{val}
        }\qquad
        \inferH{Val-Abs}{
        }{
            \Lam{x}[\sigma]{e} \ \text{val}
        }\\
        \inferH{D-Case-In-l}{
        }{
            \LamCase{\LamInl{e}}{x}{e_1}{y}{e_2} \Step e_1[e/x]
        }\qquad
        \inferH{D-Case-In-r}{
        }{
            \LamCase{\LamInr{e}}{x}{e_1}{y}{e_2} \Step e_2[e/y]
        }\\
        \inferH{D-Case}{
            e \Step e'
        }{
            \LamCase{e}{x}{e_1}{y}{e_2} \Step \LamCase{e'}{x}{e_1}{y}{e_2}
        }\\
        \inferH{D-Prj-Pair-l}{
        }{
            \Proj{\Tuple{e_1}{e_2}} \Step e_1
        }\qquad
        \inferH{D-Prj-Pair-r}{
        }{
            \Proj[2]{\Tuple{e_1}{e_2}} \Step e_2
        }\\
        \inferH{D-Prj-l}{
            e \Step e'
        }{
            \Proj{e} \Step \Proj{e'}
        }\qquad
        \inferH{D-Prj-r}{
            e \Step e'
        }{
            \Proj[2]{e} \Step \Proj[2]{e'}
        }\\
        \inferH{D-Beta}{
        }{
            (\Lam{x}[\sigma]{e_1})(e_2) \Step e_1[e_2/x]
        }\qquad
        \inferH{D-App}{
            e_1 \Step e'_1
        }{
            e_1(e_2) \Step e'_1(e_2)
        }
    \end{mathpar}
    \caption{Dynamic Rules for the $\lambda$-Calculus}
    \label{fig: dr stlc}
\end{figure}

\noindent
Again we have premises above the line and conclusions below the line. However, here 
we make use of $e_1 \Step e_2$ to signify a transition from one term to another. This 
transition can be thought of as a change of state from $e_1$ to $e_2$. Clearly, any 
``val'' rule simply states that terms of the given structure are values and thus cannot 
transition. Apart from these val rules, we have two distinct transition types: instruction 
transitions which perform computation and require no premises, and search transitions 
which allow for subterm computation. Together these determine the order of evaluation of 
terms. If we can perform a search transition on some term then we must do so before performing 
an instruction transition. For each instruction transition, there is an implication that 
none of the subterms can transition to another state while the whole term is in it's current 
state. \\

\noindent
The \ruleref{D-Case-In-l} rule substitutes $e$ for $x$ in $e_1$ if $\LamInl{e}$ is the first subterm, 
and \ruleref{D-Case-In-r} performs the same substitution in $e_2$ if we have $\LamInr{e}$ instead. 
The \ruleref{D-Case} rule transitions from a case statement with $e$ to the same case statement 
but with $e'$ if $e$ can transition to $e'$. \ruleref{D-Prj-Pair-l} offers the left projection of 
a pair, and similarly \ruleref{D-Prj-Pair-r} offers the right projection. \ruleref{D-Prj-l} and 
\ruleref{D-Prj-r} transition from the projection of $e$ to the projection of $e'$ if 
$e \Step e'$. The \ruleref{D-Beta} rule performs a beta reduction on a lambda term and replaces $x$ 
with $e_2$ in $e_1$. Finally, \ruleref{D-App} transitions from the application $e_1 (e_2)$ to 
$e'_1 (e_2)$ if $e_1 \Step e'_1$. \\

\noindent
Combining both the dynamics and statics, we can ensure that the $\lambda$-calculus is type safe 
if the following properties hold: \\

\noindent
%\textbf{Finality:} If $e$ val then there is no $e'$ where $e \Step e'$. \\\\
%\textbf{Determinism:} If $e \Step e_1$ and $e \Step e_2$ then $e_1 \equiv e_2$. \\\\
\textbf{Progress:} If we have some term $e$ where $\vdash \DeclVar{e}{\tau}$ either $e$ is a 
value, or $e \Step e'$ for some $e'$. \\\\
\textbf{Preservation:} If we have $\vdash \DeclVar{e}{\tau}$ and $e \Step e'$ we must have 
$\vdash \DeclVar{e'}{\tau}$. \\

\noindent
Progress states that computation will continue until evaluation is complete, i.e. until we have a 
value. Preservation tells us that types are preserved under evaluation. Together they show that 
well-typed programs don't go wrong. 

%proof of progress and preservation for stlc?

% -----------------------------------------------------------------------------
